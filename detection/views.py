import cv2
from django.http import StreamingHttpResponse
from django.shortcuts import render
from ultralytics import YOLO
from collections import Counter
import os

# Load model
model = YOLO("yolov8s.pt")

# Bi·∫øn l∆∞u tr·ªØ k·∫øt qu·∫£ nh·∫≠n di·ªán qua c√°c frame
detection_buffer = []
BUFFER_SIZE = 10  # ƒê·ªß 10 frame m·ªõi x·ª≠ l√Ω
last_spoken_object = None  # Tr√°nh ph√°t √¢m l·∫∑p l·∫°i li√™n t·ª•c

# Dictionary d·ªãch sang ti·∫øng Vi·ªát (th√™m c√°c t·ª´ b·∫°n c·∫ßn)
TRANSLATIONS = {
    'person': 'ng∆∞·ªùi',
    'laptop': 'm√°y t√≠nh x√°ch tay',
    'phone': 'ƒëi·ªán tho·∫°i',
    'cup': 'c·ªëc',
    'bottle': 'chai',
    'book': 's√°ch',
    'keyboard': 'b√†n ph√≠m',
    'mouse': 'chu·ªôt',
    'chair': 'gh·∫ø',
    'desk': 'b√†n',
    'monitor': 'm√†n h√¨nh',
    'cell phone': 'ƒëi·ªán tho·∫°i di ƒë·ªông',
    'tv': 'tivi',
    'remote': 'ƒëi·ªÅu khi·ªÉn',
    'clock': 'ƒë·ªìng h·ªì',
    'backpack': 'ba l√¥',
    'handbag': 't√∫i x√°ch',
    'tie': 'c√† v·∫°t',
    'umbrella': '√¥',
    'car': '√¥ t√¥',
    'bicycle': 'xe ƒë·∫°p',
    'dog': 'ch√≥',
    'cat': 'm√®o',
    'bird': 'chim',
}


def speak_object(object_name, language='vi'):
    """Ph√°t √¢m t√™n ƒë·ªì v·∫≠t qua loa"""
    if language == 'vi':
        # D·ªãch sang ti·∫øng Vi·ªát
        text = TRANSLATIONS.get(object_name.lower(), object_name)
        # D√πng gi·ªçng ti·∫øng Vi·ªát (n·∫øu c√≥ c√†i)
        os.system(f'say -v "Thi" "{text}"')
    else:
        # Gi·ªçng Anh M·ªπ
        text = object_name
        os.system(f'say -v "Samantha" "{text}"')


def gen_frames():
    global detection_buffer, last_spoken_object

    cap = cv2.VideoCapture(0)
    frame_count = 0

    while True:
        success, frame = cap.read()
        if not success:
            break

        frame_count += 1

        # Nh·∫≠n di·ªán v·ªõi model (t·∫Øt verbose log)
        results = model(frame, stream=True, conf=0.5, verbose=False)

        # L·∫•y object c√≥ confidence cao nh·∫•t trong frame n√†y
        best_detection = None
        best_conf = 0

        for r in results:
            for box in r.boxes:
                cls_id = int(box.cls[0])
                label = model.names[cls_id]
                conf = float(box.conf[0])

                if conf > best_conf:
                    best_conf = conf
                    best_detection = label

        # Th√™m v√†o buffer (None n·∫øu kh√¥ng c√≥ g√¨)
        detection_buffer.append(best_detection)

        # Gi·ªõi h·∫°n buffer size
        if len(detection_buffer) > BUFFER_SIZE:
            detection_buffer.pop(0)

        # Khi ƒë·ªß 10 frames, x·ª≠ l√Ω
        if len(detection_buffer) == BUFFER_SIZE:
            # L·ªçc b·ªè None (frame kh√¥ng ph√°t hi·ªán g√¨)
            valid_detections = [d for d in detection_buffer if d is not None]

            # Ch·ªâ x·ª≠ l√Ω n·∫øu c√≥ √≠t nh·∫•t 6/10 frames ph√°t hi·ªán object
            if len(valid_detections) >= 6:
                # ƒê·∫øm object xu·∫•t hi·ªán nhi·ªÅu nh·∫•t
                counter = Counter(valid_detections)
                most_common_object, count = counter.most_common(1)[0]

                # N·∫øu object n√†y kh√°c v·ªõi object v·ª´a n√≥i
                if most_common_object != last_spoken_object:
                    print(f"\nüîç DETECTED: {most_common_object.upper()}")
                    print(
                        f"   Confidence: {count}/{len(valid_detections)} frames ({count / len(valid_detections) * 100:.1f}%)")
                    print(f"   Frame: {frame_count}")
                    print("-" * 50)

                    # Ph√°t √¢m (ch·ªçn 'vi' ho·∫∑c 'en')
                    speak_object(most_common_object, language='en')

                    last_spoken_object = most_common_object

            # Reset buffer
            detection_buffer = []

        # Hi·ªÉn th·ªã frame g·ªëc (kh√¥ng v·∫Ω g√¨)
        ret, buffer = cv2.imencode('.jpg', frame)
        frame_bytes = buffer.tobytes()

        yield (b'--frame\r\n'
               b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')

    cap.release()


def video_feed(request):
    return StreamingHttpResponse(gen_frames(),
                                 content_type='multipart/x-mixed-replace; boundary=frame')


def home(request):
    return render(request, "detect.html")